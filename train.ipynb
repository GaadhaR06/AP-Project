{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee7485e-b878-4d38-bc45-4aeaf99db989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59bf054-af68-4abd-bbe9-13d44e06cc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "# Load your dataset with a different encoding\n",
    "data = pd.read_csv(\"TerrDB1.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "\n",
    "# Fill missing or blank 'nkill' values with 0\n",
    "data['nkill'] = data['nkill'].apply(lambda x: 0 if pd.isnull(x) or x == '' else x)\n",
    "\n",
    "# Verify that 'nkill' has been handled\n",
    "print(data['nkill'].isnull().sum())  # Should output 0 for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11f94908-4d16-4052-89c6-a5af0dde477f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "eventid       0\n",
      "iyear         0\n",
      "imonth        0\n",
      "iday          0\n",
      "             ..\n",
      "INT_LOG       0\n",
      "INT_IDEO      0\n",
      "INT_MISC      0\n",
      "INT_ANY       0\n",
      "related       0\n",
      "Length: 72, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop(columns=['nkill'])  # Independent variables\n",
    "y = data['nkill'].apply(lambda x: 0 if x == 0 else (1 if x == 1 or x == 2 else 2))  # Categorized target variable\n",
    "\n",
    "# Impute missing values in independent variables\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Verify that the imputation was successful\n",
    "print(X_imputed.isnull().sum())  # Should output 0 for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90009b16-0c2d-42ed-bd0a-be94e32bfb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0_1  Unnamed: 0_2  Unnamed: 0_3  Unnamed: 0_4  Unnamed: 0_5  \\\n",
      "0           0.0           0.0           0.0           0.0           0.0   \n",
      "1           1.0           0.0           0.0           0.0           0.0   \n",
      "2           0.0           1.0           0.0           0.0           0.0   \n",
      "3           0.0           0.0           1.0           0.0           0.0   \n",
      "4           0.0           0.0           0.0           1.0           0.0   \n",
      "\n",
      "   Unnamed: 0_6  Unnamed: 0_7  Unnamed: 0_8  Unnamed: 0_9  Unnamed: 0_10  ...  \\\n",
      "0           0.0           0.0           0.0           0.0            0.0  ...   \n",
      "1           0.0           0.0           0.0           0.0            0.0  ...   \n",
      "2           0.0           0.0           0.0           0.0            0.0  ...   \n",
      "3           0.0           0.0           0.0           0.0            0.0  ...   \n",
      "4           0.0           0.0           0.0           0.0            0.0  ...   \n",
      "\n",
      "   related_202003050018, 202003050023  related_202004010004, 202004010005  \\\n",
      "0                                 0.0                                 0.0   \n",
      "1                                 0.0                                 0.0   \n",
      "2                                 0.0                                 0.0   \n",
      "3                                 0.0                                 0.0   \n",
      "4                                 0.0                                 0.0   \n",
      "\n",
      "   related_202004050030, 202004050031  related_202004190023, 202004200027  \\\n",
      "0                                 0.0                                 0.0   \n",
      "1                                 0.0                                 0.0   \n",
      "2                                 0.0                                 0.0   \n",
      "3                                 0.0                                 0.0   \n",
      "4                                 0.0                                 0.0   \n",
      "\n",
      "   related_202005200016, 202005200017  related_202006120012, 202006120013  \\\n",
      "0                                 0.0                                 0.0   \n",
      "1                                 0.0                                 0.0   \n",
      "2                                 0.0                                 0.0   \n",
      "3                                 0.0                                 0.0   \n",
      "4                                 0.0                                 0.0   \n",
      "\n",
      "   related_202009040009, 202009040010  related_202009280023, 202009280024  \\\n",
      "0                                 0.0                                 0.0   \n",
      "1                                 0.0                                 0.0   \n",
      "2                                 0.0                                 0.0   \n",
      "3                                 0.0                                 0.0   \n",
      "4                                 0.0                                 0.0   \n",
      "\n",
      "   related_202009300014, 202009300015  related_202010090012, 202010090013  \n",
      "0                                 0.0                                 0.0  \n",
      "1                                 0.0                                 0.0  \n",
      "2                                 0.0                                 0.0  \n",
      "3                                 0.0                                 0.0  \n",
      "4                                 0.0                                 0.0  \n",
      "\n",
      "[5 rows x 81822 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding for categorical variables\n",
    "categorical_columns = X_imputed.select_dtypes(include=['object']).columns\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X_imputed[categorical_columns]), columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Combine the encoded categorical columns with the rest of the data\n",
    "X_imputed = X_imputed.drop(columns=categorical_columns)\n",
    "X = pd.concat([X_imputed, X_encoded], axis=1)\n",
    "\n",
    "# Verify the final feature set\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b12c0407-af05-4eaf-8478-2572a6c776e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11143, 81822) (2786, 81822)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the shape of the data\n",
    "print(X_train.shape, X_test.shape)  # Verify if the data split worked correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75a8fc5e-70e2-4bcc-8439-6fc9d421225c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imputer.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model and encoder to files\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "joblib.dump(encoder, 'one_hot_encoder.pkl')\n",
    "joblib.dump(imputer, 'imputer.pkl')  # Save the imputer for independent variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8219ada-2eb6-4bc1-804c-91536a7c1a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
