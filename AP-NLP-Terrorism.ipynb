{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309f3e9c-9a3e-4fdb-97e5-8e76edfaa3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is the NLP part of Analytics Project\n",
    "#First "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee36cfe-3841-4800-adcd-ada32fdba209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install googlesearch-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088620b6-a7e1-4853-83a7-8cd8dfcd3b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e5bcbf-4314-42be-aab3-929af894169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d091f3ab-78db-4d94-a4ea-7e5774453b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d72339b5-4c03-4c74-b291-e27a49cb0ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForSequenceClassification: ['model.decoder.version', 'model.encoder.version']\n",
      "- This IS expected if you are initializing TFBartForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBartForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBartForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Shiv Sena (1966–2022) (Śiva Sēnā; lit. 'Army of Shivaji'; abbr. SS) was a right-wing Marathi regionalist Hindutva-based political party in India founded in 1966 by Bal Thackeray, who was later succeeded by Uddhav Thackeray.[16][17] The party  is split into two parties: the Uddhav Thackeray-led Shiv Sena (Uddhav Balasaheb Thackeray) which has a new symbol of Mashaal (Torch) and Eknath Shinde-led Shiv Sena (2022–present) which has gotten hold of the original party name and the \"bow and arrow\" symbol.  \n",
      " Initially apolitical, the organisation was patronised by the then Chief Minister Vasantrao Naik who used it for curbing trade unions and maintain stranglehold of the Congress.[18][19][20] The organisation at the same time carried out pro-Marathi nativist movement in Mumbai in which it agitated for preferential treatment for the Marathi people over migrants from other parts of India.[21]\n",
      " Although Shiv Sena's primary base always remained in Maharashtra, it tried to expand to a pan-Indian base. In the 1970s, it gradually moved from advocating a pro-Marathi ideology to supporting a broader Hindu nationalist agenda,[22] and aligned itself with the Bharatiya Janata Party (BJP).\n",
      "The group is: Religious Terrorist Group\n"
     ]
    }
   ],
   "source": [
    "from googlesearch import search\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from transformers import pipeline \n",
    "import pandas as pd\n",
    "\n",
    "# names_sheet=pd.read_excel('GroupName_terrorists.xlsx')\n",
    "# names_sheet.dropna()\n",
    "# df=pd.DataFrame(names_sheet)\n",
    "\n",
    "########################################################################################\n",
    "# Initialize the zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def get_first_google_link(gname):\n",
    "    for result in search(gname, num_results=10):\n",
    "        if 'wikipedia.org' in result:\n",
    "            return result\n",
    "        elif 'satp.org' in result:\n",
    "            return result\n",
    "\n",
    "    # print(\"got first google link\")\n",
    "    return None\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "def get_textual_content(group_name):\n",
    "    # Get the first two sentences from the Wikipedia page\n",
    "    # print(\"Got group name\")\n",
    "    first_link = get_first_google_link(group_name)\n",
    "    if first_link:\n",
    "        url = first_link\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            paragraphs = soup.find_all('p') \n",
    "            \n",
    "            # Extract text from the paragraphs\n",
    "            text = ' '.join([para.get_text() for para in paragraphs]) #getting full content of wikipedia\n",
    "            \n",
    "            # Split the text into sentences\n",
    "            sentences = text.split('. ')\n",
    "            \n",
    "            # Return the first four sentences\n",
    "            op = '. '.join(sentences[:4]) + '.' if len(sentences) > 1 else None #if len(text)=1 it means text=name of grp\n",
    "            print(op)\n",
    "            return op\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "def classify_group(text):\n",
    "    \n",
    "    classes_labels = [\"Religious Terrorist Group\", \"Separatist Terrorist\", \"Left-Wing Terrorist Group\", \"Right-Wing Terrorist Group\", \"Non terrorist Group\"]\n",
    "    result = classifier(text, classes_labels)\n",
    "    return (result['labels'][0])\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "# classified_list=[]\n",
    "# group_names = df['GNAME'].to_list()  \n",
    "\n",
    "# for group in group_names:\n",
    "#     content = get_textual_content(group)\n",
    "#     if content!= None:\n",
    "#         classified_list.append(classify_group(content))\n",
    "#     else: \n",
    "#         classified_list.append('No information on Group')\n",
    "\n",
    "group = 'Shiv Sena'\n",
    "content = get_textual_content(group)\n",
    "classgrp = classify_group(content)\n",
    "print(\"The group is:\", classgrp)\n",
    "\n",
    "# length=len(df['GNAME'])-len(classified_list)\n",
    "\n",
    "# for i in range(length):\n",
    "#     classified_list.append('dummy')\n",
    "\n",
    "# df['Classification']=classified_list\n",
    "# print(df[['GNAME', 'Classification']])\n",
    "\n",
    "# df.to_excel('output_file.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1155948-2278-4bfa-85f8-88d2e88af4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (1.42.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (1.5.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.25.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gadha\\anaconda3\\envs\\env_nlp\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4ef1f-6208-437d-bc19-926f317e486c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ENV_NLP]",
   "language": "python",
   "name": "conda-env-ENV_NLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
